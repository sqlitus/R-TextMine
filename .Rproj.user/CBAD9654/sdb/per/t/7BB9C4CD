{
    "collab_server" : "",
    "contents" : "################################################\n# Import Extended Metrics\n# 7/13/2017 - Plot Weekly or Monthly Totals\n################################################\n\nipak <- function(pkg){\n  new.pkg <- pkg[!(pkg %in% installed.packages()[, \"Package\"])]\n  if (length(new.pkg)) \n    install.packages(new.pkg, dependencies = TRUE)\n  sapply(pkg, require, character.only = TRUE)\n}\n\nipak(\"checkpoint\")\ncheckpoint(\"2017-07-12\")\npackages <- c(\"ggplot2\", \"tm\", \"sqldf\", \"qdap\", \"scales\")\nipak(packages)\n\n\n# read from sharefile, clean, transform, calculate columns\nfile_loc <- \"\\\\\\\\cewp1650\\\\Chris Jabr Reports\\\\Extended Metrics.csv\"\nx <- read.csv(file_loc, header = TRUE)\n\n# clean/transform\ncolnames(x)[1] <- \"id\"\nx$Title <- as.character(x$Title)\nx$Created_Date <- as.Date(x$Created_Date, \"%m/%d/%Y\")\nx$Resolved_Date <- as.Date(x$Resolved_Date, \"%m/%d/%Y\")\n\n# Create Week / Month \"variables\" \nx$Created_Week_R <- as.Date(cut(x$Created_Date, breaks = \"week\"))\nx$Created_Month_R <- as.Date(cut(x$Created_Date, breaks = \"month\"))\n\nggplot(x, aes(Created_Month_R, Open_To_Resolve_Time__M_))+ \n  stat_summary(fun.y = sum, geom = \"bar\")+\n  scale_x_date(labels = date_format(\"%Y-%m\"), breaks = \"1 month\")\n\n\n\n# Count\nggplot(x, aes(Created_Month_R))+\n  geom_bar()\n\n# Sum\nggplot(x, aes(Created_Month_R, Open_To_Resolve_Time__M_))+\n  stat_summary(fun.y = \"sum\", geom = \"bar\")\n\n# Avg\nggplot(x, aes(Created_Month_R, Open_To_Resolve_Time__M_))+\n  stat_summary(fun.y = \"mean\", geom = \"bar\")\n\n\nggplot(x, aes(Created_Month_R, Open_To_Resolve_Time__M_))+\n  stat_summary(fun.y = \"sum\", geom = \"bar\")+\n  scale_x_date(date_breaks = \"4 month\")\n\n# text mine as corpus\n# x.1 <- x[,c(\"id\",\"Title\")]\n# corp <- Corpus(DataframeSource(x.1))\n# dtm <- DocumentTermMatrix(corp)\n\n\n\n\n################################################\n# FACET EXTENDED METRICS\n# 7/10/2017\n################################################\n\nlibrary(ggplot2)\nlibrary(sqldf)\n\nx.2 <- sqldf(\"select * from [x] where ONEPOS_LIST = 1\") # not null\n\nggplot(data=x, aes(x=Created_Week, y=Open_To_Resolve_Time__M_))+\n  # stat_summary(geom=\"line\", fun.y=\"mean\") +\n  geom_line()+\n  facet_wrap(facets=~LAST_SUPPORT_GROUP)+ # rows ~ columns\n  ggtitle(\"Mean Time Restore Service\")+\n  xlab(\"Week\")+\n  ylab(\"Avg Min Restore Service\")\n\n\n\n\n\n\n################################################\n# analyzing text documents by row workflow\n# 7/11/2017\n################################################\n\npackages <- c(\"qdap\",\"ggplot2\")\nipak(packages)\n\n\nDATA \ndput(head(DATA))\n\nfreqs <- t(wfm(DATA$state, 1:nrow(DATA))) \n# Data frame with all word counts\ndf.txt1 <- data.frame(DATA, freqs, check.names = FALSE) \n\n# Data frame with top 9 word counts\nords <- rev(sort(colSums(freqs)))[1:9] #top 9 words \ntop9 <- freqs[, names(ords)] #grab those columns from freqs\nDATA.top9 <- data.frame(DATA, top9, check.names = FALSE) #put it together\n\n\n\n\n# word count by row attempt 1\nfunction(firstattempt){\n# turning word count columns into flag columns\ndf2 <- df.txt1\n\ndf2 <- as.data.frame(sapply(df2[-c(1:5)],function(i){\n  ifelse(i>0,1,0)}))\n\n# Data frame with all words & flags\ndf2 <- cbind(df.txt1[1:5],df2)\n\ndf2.ords <- rev(sort(colSums(df2[-c(1:5)])))[1:15] #top 9 words BY ROW (IR) OCCURENCE\ndf2.top15 <- df2[,names(df2.ords)] #grab columns names of the \"top 15\"\ndf2.wf <- data.frame(df2, df2.top15, check.names = F)\n} \n\n\n#########\n# EXTENDED METRICS WORD COUNT BY ROW - TITLE\n# need to strip whitespace, etc.\n# Reference: R text mining doc & https://stackoverflow.com/questions/30900229/performing-text-analytics-on-a-text-column-in-dataframe-in-r\n#########\n\nem <- x\n\nem$Title <- tolower(em$Title)\n# em$Title <- tm::removeNumbers(em$Title)\nem$Title <- tm::removeWords()\n\nem$Title\n\nem.freqs <- t(wfm(em$Title, 1:nrow(em)))\n",
    "created" : 1499889754602.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2776239802",
    "id" : "7BB9C4CD",
    "lastKnownWriteTime" : 1500078716,
    "last_content_update" : 1500078716,
    "path" : "C:/Work/Git/Repos/R-TextMine/Work.R",
    "project_path" : "Work.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}